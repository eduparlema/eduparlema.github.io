{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6900646c-bfc2-4b81-bb08-d1ed51e0df79",
   "metadata": {},
   "source": [
    "---\n",
    "title: Learning from Dr. Timnit Gebru \n",
    "author: Eduardo Pareja Lema\n",
    "date: '2023-04-19'\n",
    "image: \"gebru.jpeg\" \n",
    "description: \"A reflective blog post on Dr. Timnit Gebru's talk at Middlebury\"\n",
    "format: html \n",
    "--- "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ddddb862",
   "metadata": {},
   "source": [
    "# Overview \n",
    "\n",
    "On April 24th, 20203, Dr. Timnit Gebru is virtually visiting our Machine Learning class where she will share her outstanding work on biases in image recognition. Later this day, Dr. Gebru is giving a talk to the Middlebury College campus on \"Eugenics and the Promise of Utopia thourhg Artificial General Intelligence.\" Dr. Timnit Gebru is a leading computer scientist focused on the study of artificial intelligence, algorithmic bias, and ethics in technology. She is an advocate for diversity and inclusion in the tech industry and her work on the ethical implications of AI has been particularly influential. She has recently been named on of Fortune's 50 Greatest Leaders and one of Time's 100 for 2022. Moreover, she is the founder and executive director of the Distributed Artificial Intelligence Research Institue (DAIR) whose mission is to ensure that the deployment of AI include diverse perspectives. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "83307757",
   "metadata": {},
   "source": [
    "## Dr. Gebru's talk at FATE in Computer Vision \n",
    "\n",
    "During her talk as part of a Tutorial on Fairness, Accountability, Transparency, and Ethics (FATE) in Computer Vision, Dr. Gebru raised a couple of very interesting points. She started the talk by providing some example of how computer vision can have negative impacts. For instance, if face recognition were to be used to assess a candidate's personal traits for a job, there could be a glitch that only highlights negative behavior in individuals. The worrying thing is that if we do not regularize these things and these kind of software is used worldwide, some people could potentially get rejected from every single job they apply to. Dr. Gebru highlights the following quote: \n",
    "\n",
    "***<p style=\"text-align: center;\">\"Every data set involving people implies subjects and objects, those who collect and those who make up the collected. It is imperative to remember that on both sides we have human beings.\" (Mimi Onuoha, Data & Society)</p>***\n",
    "\n",
    "Dr. Gebru raises the concern of the lack of diversity in datasets. However, she claims that this is not an AI-specific problem, instead this occurs in many areas, like drug-testing or crash-test dummies. Even though this is concerning in itself, this is not the biggest problem. Including more diverse datasets is not the solution, as Dr. Gebru says, \"Visibility is not inclusion.\" We cannot ignore social and structural problems. Making something fair is not just about making something work equally well for everybody. We must ask ourselves, \"why do we need these technologies?\". \"Why do we need gender classifiers?\". \"Couldn't these be used for advertising targeted to a gender we believe might consume a product?\". \"Wouldn't this perpetuate gender stereotypes?\"\n",
    "\n",
    "All in all, what everyone must understand about computer vision these days is that the racial problems present in this field only mirror our societal problems. Making data more diverse does not fix the problem, in fact, it kinda of overlooks the problem of working towards a solution to our societal and structural problems. \n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "89f523c7",
   "metadata": {},
   "source": [
    "## Question for Dr. Gebru\n",
    "\n",
    "It seems that evolving AI is not only skewed towards the creator's world views but also to overpower those who lack the skills, do you think that making the development of AI more accesible to people would diminish the negative impacts of this disruptive field? "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "76fa8127",
   "metadata": {},
   "source": [
    "# Dr. Gebru's Talk \"at\" Middlebury \n",
    "\n",
    "In the evening of April 24th, Dr. Gebru gave a virtual talk at Middlebury College on \"Eugenics and the Promise of Utopia through Artificial General Intelligence\". In this talk Dr. Gebru raised many interesting points. She first began by showing some claims that we cannot even grasph the limittless potentials of AGI (Artificial General Intelligence). Nowadays, with rapid-growing technologies such as Chat-GPT or DALL-E, such claims have become popular. However, why do we want to develop AGI? \n",
    "\n",
    "According to Dr. Gebru's talk, the need for developing AGI goes way back to the 20th century with eugenics. The first-wave of eugenics was the idea that we can improve the \"human stock\" through genetics and heredity. Although many people related the term eugenics with the tragedies that took place during WW2, there has been a second-wave of eugenics through the TESCREAL ideologies. These ideologies are rooted in the idea of \"transhumanism\", the idea of not simply improving the \"human stock\", but of transcending humanity. \n",
    "\n",
    "The TESCREAL ideologies are deeply realted with AGI, given that according to such ideologies its development promises a utopia in which \"humans will merge with machines\" to transcend our biological limitations. However, as Dr. Gebru points out, here lies the biggest problem. AGI might promise a utopia, but for whom? Maybe in a few years people will have access to bots such as Chat-GPT to inquire about medical concerns or have access to many other services for a much lower cost. But, who is benefitting from this? Such bots are not paying any certified medical profession nor any people whose data is being used to train such models. It seems like the ones who are benefitting are the big companies who have the power to develop and train such bots. We do not even need to imagine a possible future, nowadays there have been reports of people in developing countries who are being exploited to monitor the toxic responses of chatbots or images from generative art AI. \n",
    "\n",
    "I totally agree with Dr. Gebru's discussion. People in who are in charge of controlling and developing new technologies will keep getting more powerful and richer. However, I wish she went a little further into considering this scenario. There have always been instances in history in which a new development benefited some privileged individuals at first and then went on becoming available to most of the population. I think that AGI is a very particular case because I fear that in this case there will not be a switch when everyone could benefit from it. Depending on the direction this takes, AGI might be able to replace most of people's jobs while benefitting only big AI companies. But this time, these AI companies will be much smaller compared to the wide population. At some point a limit must be reached, a very small part of the population cannot keep benefiting from this while the vast majority is not. \n",
    "\n",
    "The interaction with Dr. Gebru was empowering. The idea of AGI is frightening in itself, but Dr. Gebru is an example of how the development of such technologies could actually take an interesting and ethical direction. We are living exciting times and we as potential future developers or researchers must bear in mind that there could be negative consequences as result of our work. Dr. Gebru definitely inspired me to continue investingating this exciting area of computer science. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml-0451] *",
   "language": "python",
   "name": "conda-env-ml-0451-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
